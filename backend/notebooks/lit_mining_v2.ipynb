{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70bb416e",
   "metadata": {},
   "source": [
    "# Lit Mining V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ceeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b0487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "def has_text(paper_path):\n",
    "    doc = fitz.open(paper_path)\n",
    "    text = doc[0].get_text()\n",
    "    \n",
    "    return len(text.strip()) < 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff62ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grobid_client.grobid_client import GrobidClient\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_paper_details(client, pdf_path):\n",
    "    \"\"\"Extract Paper Details using GROBID\"\"\"\n",
    "    # If pdf has text, extract abstract from text\n",
    "    result = client.process_pdf(\n",
    "        service='processHeaderDocument',  # Fast - only extracts header/metadata\n",
    "        pdf_file=pdf_path,\n",
    "        generateIDs=False,\n",
    "        consolidate_header=True,  # Improve accuracy with CrossRef\n",
    "        consolidate_citations=False,  # Not needed for abstract\n",
    "        include_raw_citations=False,\n",
    "        include_raw_affiliations=False,\n",
    "        tei_coordinates=False,\n",
    "        segment_sentences=False\n",
    "    )\n",
    "    # Extract XML content from tuple (pdf_file, status, xml_text)\n",
    "    _, status, result_xml = result\n",
    "    \n",
    "    if status != 200:\n",
    "        return f\"Error processing PDF: Status {status}\", \"No title found\", [], \"No date found\", \"No journal found\", \"No volume found\", \"No issue found\"\n",
    "    \n",
    "    # Parse the XML to extract abstract\n",
    "    root = ET.fromstring(result_xml)\n",
    "    ns = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "\n",
    "    # Find the abstract\n",
    "    abstract_elem = root.find('.//tei:abstract//tei:p', ns)\n",
    "    abstract = abstract_elem.text if abstract_elem is not None else \"No abstract found\"\n",
    "\n",
    "    # Extract title\n",
    "    title_elem = root.find('.//tei:title', ns)\n",
    "    title = title_elem.text if title_elem is not None else \"No title found\"\n",
    "    \n",
    "    # Extract authors\n",
    "    authors = []\n",
    "    author_elements = root.findall('.//tei:author', ns)\n",
    "    for author in author_elements:\n",
    "        name = author.find('.//tei:name', ns)\n",
    "        if name is not None:\n",
    "            authors.append(name.text)\n",
    "    \n",
    "    # Extract date\n",
    "    date_elem = root.find('.//tei:date', ns)\n",
    "    date = date_elem.text if date_elem is not None else \"No date found\"\n",
    "\n",
    "    # Extract journal\n",
    "    journal_elem = root.find('.//tei:journal', ns)\n",
    "    journal = journal_elem.text if journal_elem is not None else \"No journal found\"\n",
    "\n",
    "    # Extract volume\n",
    "    volume_elem = root.find('.//tei:volume', ns)\n",
    "    volume = volume_elem.text if volume_elem is not None else \"No volume found\"\n",
    "\n",
    "    # Extract issue\n",
    "    issue_elem = root.find('.//tei:issue', ns)\n",
    "    issue = issue_elem.text if issue_elem is not None else \"No issue found\"\n",
    "\n",
    "    return abstract, title, authors, date, journal, volume, issue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0142355a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-08 16:41:23,961 - INFO - Logging configured - Level: INFO, Console: True, File: disabled\n",
      "2025-10-08 16:41:24,038 - INFO - GROBID server http://localhost:8070 is up and running\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract for Kaneetal2012.pdf: abstract: Hawai'i's beaches are a focal point of modern lifestyle as well as cultural tradition. Yet coastal e\n",
      "Abstract for Spirandellietal2016_ImprovingAdaptationPlanningforSLR.pdf: abstract: Sea-level rise (SLR) presents risks to communities and ecosystems because of hazards like coastal er\n",
      "Abstract for sherman_JSR_1999.pdf: abstract: No abstract found\n",
      "Abstract for Romine et al 2013 Beach Erosion and SLR in HI.pdf: abstract: The islands of Oahu and Maui, Hawaii, with significantly different rates of localized sea-level rise\n",
      "Abstract for Fletcher-Chapter6-slr-hawaii.pdf: abstract: Error processing PDF: Status 500\n",
      "Abstract for CoastalSedimentary.pdf: abstract: No abstract found\n",
      "Abstract for wave_driven_cross_shore.pdf: abstract: Coastal erosion, intensified by sea level rise, poses significant threats to coastal communities in \n",
      "Abstract for Harney_Fletcher_JSR_2003.pdf: abstract: Sediments of the bay and coastal plain of Kailua (Oahu, Hawaii) are Ͼ 90% biogenic carbonate produce\n",
      "Abstract for Genz_06-0757.pdf: abstract: There is a need to supply coastal managers with statistically defensible hazard predictions that can\n",
      "Abstract for Genz_06-0756.pdf: abstract: Single-transect methods of shoreline change prediction are unparsimonious, i.e., they tend to overfi\n",
      "Abstract for KCAP_ClimateWP_22_0302.pdf: abstract: No abstract found\n",
      "Abstract for ClimateBrief_low.pdf: abstract: No abstract found\n",
      "Abstract for Andrade_et_al_2023-coas-40-02-338-352.pdf: abstract: The Mac ¸ambaba Holocene coastal barrier and dune system in Rio de Janeiro state, Brazil, is located\n",
      "Abstract for RooneyCoastalSed2003.pdf: abstract: Beaches serve as important recreational, cultural, and ecological resources, and as an indispensable\n",
      "Abstract for Romine et al 2016 Beach Erosion Under Rising Sea Level.pdf: abstract: This study addresses gaps in understanding the relative roles of sea-level change, coastal geomorpho\n",
      "Abstract for s10584-018-2327-7.pdf: abstract: Coastal land use in the USA is regulated by a chain of integrated federal to local policies that emp\n",
      "Abstract for Bochicchio_etal_2009.pdf: abstract: Hawaiian fringing reefs display sand bodies on their surfaces that are potentially important compone\n",
      "Abstract for remotesensing-12-00154.pdf: abstract: Majuro Atoll in the central Pacific has high coastal vulnerability due to low-lying islands, rising \n",
      "Abstract for Conger_TGARS.pdf: abstract: We have developed a simple technique to decorrelate remote sensing color band data from depth in opt\n",
      "Abstract for annurev-marine-020923-120737.pdf: abstract: No abstract found\n",
      "Abstract for KaneEtAl2014_SLRCriticalElevation.pdf: abstract: Coastal strand and wetland habitats in the Hawaiian Islands are often intensively managed to restore\n",
      "Abstract for HawaiiReef_07.pdf: abstract: The coastal region of Oahu, Hawaiian Islands, is underlain by a system of carbonate strata (calcaren\n",
      "Abstract for 1-s2.0-S2213305421000163-main.pdf: abstract: In Hawai'i, as is the case globally, sea level rise threatens the availability of suitable habitat f\n",
      "Abstract for ClimateChangeFSM.pdf: abstract: No abstract found\n",
      "Abstract for Cooper_etal_2013.pdf: abstract: Sea-level rise (SLR) threatens islands and coastal communities due to vulnerable infrastructure and \n",
      "Abstract for ofr2011-1051_report_508.pdf: abstract: No abstract found\n",
      "Abstract for Jrooney2000.pdf: abstract: This study examines historical shoreline change in southwestern Maui, Hawaii based on orthophotos fo\n",
      "Abstract for MappingShorelineCh106-124.pdf: abstract: No abstract found\n",
      "Abstract for Cooper_etal_2012.pdf: abstract: No abstract found\n",
      "Abstract for IsounCoralReefs03.pdf: abstract: We used high-resolution, airborne, digilal, multi-spectral imagery to map bathymetry and the percent\n",
      "Abstract for Bochicchio_Marine_Geo09.pdf: abstract: photographic, sedimentological, and computer modeling techniques: Lanikai and Bellows Beaches, Oahu,\n",
      "Abstract for ARCC2023Proceedings.pdf: abstract: No abstract found\n",
      "Abstract for CS2003_Norcross_LongshoreTransport.pdf: abstract: The offshore environment of many of Hawaii's sandy beaches is characterized by shallow limestone sur\n",
      "Abstract for d41586-024-00917-9.pdf: abstract: No abstract found\n",
      "Abstract for Hawaii_Natural_Resources_Law_Enforcement_Manual.10.17.2022.pdf: abstract: No abstract found\n",
      "Abstract for 2024_Illustrating_Urban_Plans_Meguro_et_al.pdf: abstract: Academic research plays a pivotal role in illustrating and testing potential future adaptation strat\n",
      "Abstract for Maui Shoreline Rules Chapter 203 - Dr. Chip Fletcher Testimony.pdf: abstract: No abstract found\n",
      "Abstract for FletcherEtAl1990.pdf: abstract: Modern facies-distribution patterns, extensive core data, and chronostratigraphic cross sections pro\n",
      "Abstract for 230125_Final Booklet.pdf: abstract: No abstract found\n",
      "Abstract for HarneyCoralReefs2000.pdf: abstract: The origin, age. and dynamics of carbonate sediments in Kailua Bay on Oahu, Hawaii, are described. T\n",
      "Abstract for Habel_Waikiki_replen_Coastal_eng_2016.pdf: abstract: Royal Hawaiian Beach, located in Waikiki, Hawaii received sand nourishment of 17,551 m 3 during the \n",
      "Abstract for CoralReefsEngels.pdf: abstract: Twelve cores from the protected reef-Xat of Molokai revealed that carbonate sediment accumulation, r\n",
      "Abstract for Anderson_et_al_SciRep_2018_SLR_modeling.pdf: abstract: Planning community resilience to sea level rise (SLR) requires information about where, when, and ho\n",
      "Abstract for Habel_et_al_flood_comparison.pdf: abstract: Sea-level rise (SLR) induced flooding is often envisioned as solely originating from a direct marine\n",
      "Abstract for Sherman et al_QuatRes_v81_p138-150.pdf: abstract: In situ Pleistocene reefs form a gently sloping nearshore terrace around the island of Oahu. TIMS Th\n",
      "Abstract for fletcher2009_sealevelreview.pdf: abstract: The rate of global mean sea-level rise (~3 mm/yr; SLR) has accelerated compared to the mean of the 2\n",
      "Abstract for s10584-023-03602-4.pdf: abstract: Climate change-induced sea level rise (SLR) will affect a range of coastal assets and prompt difficu\n",
      "Abstract for KaneEtAl2014_RankedManagementConcerns.pdf: abstract: Coastal strand and wetland habitats are intensively managed to restore and maintain populations of e\n",
      "Abstract for Cochrane_etal2015.pdf: abstract: Between 3050 and 2700 years ago, humans first colonized the islands of southwest Remote Oceania, a r\n",
      "Abstract for Grossman_Fletcher_JSR_2003.pdf: abstract: Analyses of 32 drill cores obtained from the windward reef of Kailua Bay, Oahu, Hawaii, indicate tha\n",
      "Abstract for 43UHawLRev464.pdf: abstract: No abstract found\n",
      "Abstract for Lander_et al_Envisioning_In-Situ_Sea_Level_Rise_Adaptation_for_Coastal_Cities.pdf: abstract: No abstract found\n",
      "Abstract for Andrade et al 2023.pdf: abstract: The Mac ¸ambaba Holocene coastal barrier and dune system in Rio de Janeiro state, Brazil, is located\n",
      "Abstract for Conger_marinegeo_2009.pdf: abstract: Sandy substrate is important as a resource, habitat, and dynamic region of the bathymetry. We find t\n",
      "Abstract for Romine_coas-25-04-17.pdf: abstract: Here we present shoreline change rates for the beaches of southeast Oahu, Hawaii, calculated using r\n",
      "Abstract for Kane2017_QuaternaryResearch.pdf: abstract: Coastal plain stratigraphy is often over looked in paleo-sea-level reconstructions because carbonate\n",
      "Abstract for Kurylyketal.2025NCities.pdf: abstract: No abstract found\n",
      "Abstract for Rubin_Fletcher_Sherman2001.pdf: abstract: Giant tsunamis, generated by submarine landslides in the Hawaiian Islands, have been thought to be r\n",
      "Abstract for s41597-024-03160-z.pdf: abstract: In this dataset, we present 128 coastal surveys conducted between 2018 and 2021 at Kahaloa Beach, al\n",
      "Abstract for Romine_SCD08.pdf: abstract: Digital aerial photo mosaics and NOAA topographic survey charts (t-sheets) are used to map historica\n",
      "Abstract for Vitousek_PSC08.pdf: abstract: The goal of this study was to determine the maximum annually recurring wave height approaching Hawai\n",
      "Abstract for VitouseketalProceeding07.pdf: abstract: Kaanapali beach is a well-defined littoral cell of carbonate sand extending 2 km south from Black Ro\n",
      "Abstract for SLR_Constraint_District_Ordinance.pdf: abstract: SECTION 1. Finding and Purpose. The Council finds that rapid warming of the atmosphere and oceans is\n",
      "Abstract for Fletcher-Chapter7-climate-change.pdf: abstract: Error processing PDF: Status 500\n",
      "Abstract for Act-238_HSEO_Decarbonization_Report.pdf: abstract: No abstract found\n",
      "Abstract for Vitouseketal_NatureSR2017.pdf: abstract: No abstract found\n",
      "Abstract for KailuaBay.pdf: abstract: Historical aerial photographs and topographic survey sheets are used to establish a 70-year shorelin\n",
      "Abstract for 230131_Final Booklet.pdf: abstract: No abstract found\n",
      "Abstract for BeachManagementPlan_1992_scanned.pdf: abstract: Error processing PDF: Status 500\n",
      "Abstract for GenzetalProceeding.pdf: abstract: We evaluate three classes of shoreline change rate methods on all sandy beaches of Maui: 1) methods \n",
      "Abstract for 1-s2.0-S002532272200041X-main.pdf: abstract: Royal Hawaiian Beach in Waikīkī plays an essential role in Hawai'i's tourism-based economy. To infor\n",
      "Abstract for Kane_et_al_2015_ClimateChange.pdf: abstract: No abstract found\n",
      "Abstract for ReefAccretionElNino.pdf: abstract: New observations of reef accretion from several locations show that in Hawai'i accretion during earl\n",
      "Abstract for ClimateChange_in_FSM.pdf: abstract: No abstract found\n",
      "Abstract for HabelEtal_WR_2017.pdf: abstract: Many of the world's largest cities face risk of sea-level rise (SLR) induced flooding owing to their\n",
      "Abstract for OCCL23-Sea-Level-Rise-Report-FY22-1.pdf: abstract: No abstract found\n",
      "Abstract for Norcross_SCD08.pdf: abstract: Maui's coastal lands, along with many others worldwide, are under tremendous pressure from expanding\n",
      "Abstract for i2761.pdf: abstract: No abstract found\n",
      "Abstract for Fletcher_KaPili_Kai_09.pdf: abstract: No abstract found\n",
      "Abstract for FletcherEtAl1993_SLRAccelerationandDrowningofDelawareBayCoast18k.pdf: abstract: Cores from Delaware Bay tidal marshes separated by over 100 km reveal correlative transgressive over\n",
      "Abstract for Habel_2019_Environ._Res._Commun._1_041005.pdf: abstract: Groundwater inundation (GWI) is a particularly challenging consequence of sea-level rise (SLR), as i\n",
      "Abstract for remotesensing-14-05108.pdf: abstract: Small uncrewed aerial systems (sUASs) provide an efficient way to reveal processes controlling the m\n",
      "Abstract for Use surplus to protect Sunset Beach.pdf: abstract: Column: Use surplus to protect Sunset Beach Hawaii has a budget surplus of $1.9 billion. We urge use\n",
      "Abstract for WaikikiUAS_Defense_OnlineVersion.pdf: abstract: No abstract found\n",
      "Abstract for Anderson_Frazer_JCR_preprint.pdf: abstract: The traditional single-transect method for predicting long-term shoreline change uses far more param\n",
      "Abstract for GeologyofHawaiiReefs.pdf: abstract: No abstract found\n",
      "Abstract for ClimateChange_in_FSM_Exec_Summary.pdf: abstract: No abstract found\n",
      "Abstract for Rotzoll Fletcher NCC 2012.pdf: abstract: Strong evidence on climate change underscores the need for actions to reduce the impacts of sea-leve\n",
      "Abstract for Cooper_etal_2013_2.pdf: abstract: Global sea-level rise (SLR) is projected to accelerate over the next century, with research indicati\n",
      "Abstract for EngelsJSR04.pdf: abstract: Two reef systems off south Molokai, Hale 0 Lono and Hikauhi (separated by only 10 kIn), show strong \n",
      "Abstract for Vitousek_SCD08.pdf: abstract: This paper outlines a practical approach to mapping extreme wave inundation and the influence of sea\n",
      "Abstract for Anderson_etal_2014_JCR.pdf: abstract: Traditional long-term (decadal) and large-scale (hundreds of kilometers) shoreline change modeling t\n",
      "Abstract for AmSamoa Climate 2016.pdf: abstract: No abstract found\n",
      "Abstract for coastal_land_subsidence.pdf: abstract: No abstract found\n",
      "Abstract for Romine Fletcher 2013 Oahu Armoring.pdf: abstract: Coastal armoring (defined as any structure designed to prevent shoreline retreat that interacts with\n",
      "Abstract for Romine_Fletcher_inpress_HI_ShoreChange_Summary_JCR.pdf: abstract: Shoreline change was measured along the beaches of Kauai, Oahu, and Maui (Hawaii) using historical s\n",
      "Abstract for RichmondHCH2001.pdf: abstract: Seven natural phenomena have been identified as posing significant threats to coastal areas orthe Ha\n",
      "Abstract for computation_of_energetic_nearshore_waves.pdf: abstract: Three phase-resolving weakly dispersive wave models are used for 2DH (2D depth-integrated) computati\n",
      "Abstract for FletcherFiersten_Hawaiichaptercoasts.pdf: abstract: No abstract found\n",
      "Abstract for CNMI Climate 2016.pdf: abstract: No abstract found\n",
      "Abstract for Earth s Future - 2020 - Kane - Rethinking Reef Island Stability in Relation to Anthropogenic Sea Level Rise.pdf: abstract: Unprecedented rates of anthropogenic sea level rise (ASLR) and attendant wave-driven flooding and sa\n",
      "Abstract for anderson_et_al_auxiliary_materials.pdf: abstract: No abstract found\n",
      "Abstract for Anderson_et_al_2015_NaturalHazards.pdf: abstract: No abstract found\n",
      "Abstract for Coyne-MappingCoastalErosion-1999.pdf: abstract: High-density shoreline change rates are calculated for the purpose of mapping 60-year coastal erosio\n",
      "Abstract for fletcher_2024_pnas_nexus.pdf: abstract: Human development has ushered in an era of converging crises: climate change, ecological destruction\n",
      "Abstract for Paoa_et_al-2023-Scientific_Reports.pdf: abstract: Projecting sea level rise (SLR) impacts requires defining ocean surface variability as a source of u\n",
      "Abstract for Neil_Tiffany_Chip_2009.pdf: abstract: Large storms make it difficult to extract the long-term trend of erosion or accretion from shoreline\n",
      "Abstract for Anderson_etal_2015_JCR.pdf: abstract: Traditional long-term (decadal) and large-scale (hundreds of kilometers) shoreline change modeling t\n",
      "Abstract for Guam Climate 2016.pdf: abstract: You may have heard the term\n",
      "Abstract for s41598-020-70577-y.pdf: abstract: Shoreline hardening, which causes beach loss globally, will accelerate with sea level rise (SLR), ca\n",
      "Abstract for anderson_et_al_GRL_2009.pdf: abstract: There is disagreement as to whether shoreline position eventually recovers from large storms. In an \n",
      "Abstract for JCOASTRES-D-11-00114.pdf: abstract: Hawai'i's beaches are a focal point of modern lifestyle as well as cultural tradition. Yet coastal e\n",
      "Abstract for GeologyGeomorphology_NWHI_Coral_Reefs2008.pdf: abstract: No abstract found\n",
      "Papers with abstracts: 78\n",
      "Papers without abstracts: 35\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = \"./pdf_pub/\"\n",
    "\n",
    "client = GrobidClient(\n",
    "        batch_size=10,\n",
    "        sleep_time=10,\n",
    "        timeout=1000\n",
    ")\n",
    "papers_with_abstracts = []\n",
    "papers_without_abstracts = []\n",
    "\n",
    "for file in os.listdir(pdf_dir):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_dir, file)\n",
    "        abstract, title, authors, date, journal, volume, issue = extract_paper_details(client, pdf_path)\n",
    "        print(f\"Abstract for {file}: abstract: {abstract[:100]}\")\n",
    "        if abstract == \"No abstract found\":\n",
    "            papers_without_abstracts.append(file)\n",
    "        else:\n",
    "            papers_with_abstracts.append({\n",
    "                \"file\": file,\n",
    "                \"abstract\": abstract,\n",
    "                \"title\": title,\n",
    "                \"authors\": authors,\n",
    "                \"date\": date,\n",
    "                \"journal\": journal,\n",
    "                \"volume\": volume,\n",
    "                \"issue\": issue\n",
    "            })\n",
    "\n",
    "print(f\"Papers with abstracts: {len(papers_with_abstracts)}\")\n",
    "print(f\"Papers without abstracts: {len(papers_without_abstracts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355fc9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write papers_with_abstracts to json\n",
    "with open(\"output/papers_with_abstracts.json\", \"w\") as f:\n",
    "    json.dump(papers_with_abstracts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84236868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marker.output import text_from_rendered\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_paper_text(pdf_path, converter, output_folder):\n",
    "    \"\"\"\n",
    "    Extract full text from a research paper\n",
    "    Returns the text as a string\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        rendered = converter(str(pdf_path))\n",
    "        text, _, _ = text_from_rendered(rendered)\n",
    "        \n",
    "        # Save\n",
    "        output_file = Path(output_folder) / f\"{Path(pdf_path).stem}.txt\"\n",
    "        output_file.write_text(text, encoding='utf-8')\n",
    "        \n",
    "        return f\"✓ {Path(pdf_path).name}\"\n",
    "    except Exception as e:\n",
    "        return f\"✗ {Path(pdf_path).name}: {e}\"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eff9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading manifest.json: 100%|██████████| 262/262 [00:00<00:00, 228kB/s]\n",
      "Downloading .gitattributes: 100%|██████████| 1.48k/1.48k [00:00<00:00, 1.06MB/s]025_09_23:   0%|          | 0/12 [00:00<?, ?it/s]\n",
      "\n",
      "Downloading special_tokens_map.json: 100%|██████████| 278/278 [00:00<00:00, 181kB/s]09_23:   8%|▊         | 1/12 [00:00<00:01,  6.37it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Downloading README.md: 100%|██████████| 5.05k/5.05k [00:00<00:00, 2.63MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Downloading training_args.bin: 100%|██████████| 7.45k/7.45k [00:00<00:00, 2.65MB/s]\n",
      "Downloading config.json: 100%|██████████| 50.4k/50.4k [00:00<00:00, 8.83MB/s]\n",
      "Downloading vocab_math.json: 100%|██████████| 20.1k/20.1k [00:00<00:00, 8.46MB/s]\n",
      "\n",
      "\n",
      "Downloading tokenizer_config.json: 100%|██████████| 694/694 [00:00<00:00, 674kB/s]\n",
      "Downloading specials_dict.json: 100%|██████████| 43.5k/43.5k [00:00<00:00, 10.1MB/s]\n",
      "Downloading preprocessor_config.json: 100%|██████████| 419/419 [00:00<00:00, 402kB/s]\n",
      "Downloading processor_config.json: 100%|██████████| 411/411 [00:00<00:00, 763kB/s]\n",
      "\n",
      "Downloading specials.json: 100%|██████████| 19.6k/19.6k [00:00<00:00, 22.0MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 1.35G/1.35G [01:00<00:00, 23.8MB/s]_09_23:  92%|█████████▏| 11/12 [00:19<00:00, 19.32it/s]\n",
      "Downloading layout model to /Users/skyler/Library/Caches/datalab/models/layout/2025_09_23: 100%|██████████| 12/12 [01:01<00:00,  5.09s/it]\n",
      "Downloading manifest.json: 100%|██████████| 262/262 [00:00<00:00, 540kB/s]\n",
      "Downloading .gitattributes: 100%|██████████| 1.48k/1.48k [00:00<00:00, 1.62MB/s]s/text_recognition/2025_09_23:   0%|          | 0/12 [00:00<?, ?it/s]\n",
      "Downloading text_recognition model to /Users/skyler/Library/Caches/datalab/models/text_recognition/2025_09_23:   8%|▊         | 1/12 [00:00<00:01,  6.24it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Downloading special_tokens_map.json: 100%|██████████| 278/278 [00:00<00:00, 73.6kB/s]\n",
      "Downloading specials_dict.json: 100%|██████████| 43.5k/43.5k [00:00<00:00, 7.91MB/s]\n",
      "Downloading preprocessor_config.json: 100%|██████████| 419/419 [00:00<00:00, 114kB/s]\n",
      "Downloading README.md: 100%|██████████| 5.05k/5.05k [00:00<00:00, 1.36MB/s]\n",
      "Downloading config.json: 100%|██████████| 50.2k/50.2k [00:00<00:00, 9.98MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Downloading vocab_math.json: 100%|██████████| 20.1k/20.1k [00:00<00:00, 6.19MB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 694/694 [00:00<00:00, 406kB/s]\n",
      "Downloading training_args.bin: 100%|██████████| 7.45k/7.45k [00:00<00:00, 5.57MB/s]\n",
      "Downloading processor_config.json: 100%|██████████| 411/411 [00:00<00:00, 459kB/s]\n",
      "Downloading specials.json: 100%|██████████| 19.6k/19.6k [00:00<00:00, 1.26MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 1.34G/1.34G [01:16<00:00, 18.9MB/s]ext_recognition/2025_09_23:  92%|█████████▏| 11/12 [00:16<00:00, 19.50it/s]\n",
      "Downloading text_recognition model to /Users/skyler/Library/Caches/datalab/models/text_recognition/2025_09_23: 100%|██████████| 12/12 [01:16<00:00,  6.38s/it]\n",
      "2025-10-08 17:06:23,107 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Downloading manifest.json: 100%|██████████| 106/106 [00:00<00:00, 272kB/s]\n",
      "Downloading table_recognition model to /Users/skyler/Library/Caches/datalab/models/table_recognition/2025_02_18:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Downloading README.md: 100%|██████████| 33.0/33.0 [00:00<00:00, 29.6kB/s]\n",
      "Downloading .gitattributes: 100%|██████████| 1.48k/1.48k [00:00<00:00, 2.89MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Downloading preprocessor_config.json: 100%|██████████| 564/564 [00:00<00:00, 367kB/s]\n",
      "Downloading config.json: 100%|██████████| 6.22k/6.22k [00:00<00:00, 5.44MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Downloading model.safetensors: 100%|██████████| 201M/201M [00:08<00:00, 24.2MB/s]\n",
      "Downloading table_recognition model to /Users/skyler/Library/Caches/datalab/models/table_recognition/2025_02_18: 100%|██████████| 5/5 [00:08<00:00,  1.77s/it]\n",
      "Downloading manifest.json: 100%|██████████| 127/127 [00:00<00:00, 213kB/s]\n",
      "Downloading README.md: 100%|██████████| 393/393 [00:00<00:00, 381kB/s]ab/models/text_detection/2025_05_07:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Downloading preprocessor_config.json: 100%|██████████| 373/373 [00:00<00:00, 80.6kB/s]\n",
      "Downloading .gitattributes: 100%|██████████| 1.48k/1.48k [00:00<00:00, 466kB/s]\n",
      "Downloading training_args.bin: 100%|██████████| 5.49k/5.49k [00:00<00:00, 1.51MB/s]\n",
      "Downloading config.json: 100%|██████████| 858/858 [00:00<00:00, 855kB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Downloading model.safetensors: 100%|██████████| 73.4M/73.4M [00:02<00:00, 26.1MB/s]\n",
      "Downloading text_detection model to /Users/skyler/Library/Caches/datalab/models/text_detection/2025_05_07: 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "Downloading manifest.json: 100%|██████████| 161/161 [00:00<00:00, 212kB/s]\n",
      "Downloading ocr_error_detection model to /Users/skyler/Library/Caches/datalab/models/ocr_error_detection/2025_02_18:   0%|          | 0/8 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "Downloading special_tokens_map.json: 100%|██████████| 695/695 [00:00<00:00, 266kB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Downloading tokenizer_config.json: 100%|██████████| 1.17k/1.17k [00:00<00:00, 251kB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Downloading config.json: 100%|██████████| 647/647 [00:00<00:00, 90.9kB/s]\n",
      "Downloading .gitattributes: 100%|██████████| 1.48k/1.48k [00:00<00:00, 1.19MB/s]\n",
      "\n",
      "\n",
      "Downloading README.md: 100%|██████████| 32.0/32.0 [00:00<00:00, 71.6kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 972k/972k [00:00<00:00, 15.2MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading tokenizer.json: 100%|██████████| 2.78M/2.78M [00:00<00:00, 14.7MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Downloading model.safetensors: 100%|██████████| 258M/258M [00:09<00:00, 28.0MB/s]\n",
      "Downloading ocr_error_detection model to /Users/skyler/Library/Caches/datalab/models/ocr_error_detection/2025_02_18: 100%|██████████| 8/8 [00:09<00:00,  1.23s/it]\n",
      "Recognizing Layout: 100%|██████████| 7/7 [00:51<00:00,  7.34s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 2/2 [00:00<00:00,  2.38it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "Recognizing Text: 100%|██████████| 51/51 [04:43<00:00,  5.56s/it]\n",
      "Recognizing Text: 100%|██████████| 2/2 [00:11<00:00,  5.67s/it]\n",
      "Recognizing tables: 100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "Detecting bboxes: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted full text for Kaneetal2012.pdf\n",
      "Extracted full text for 0 papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-08 17:12:46,778 [WARNING] surya: `TableRecEncoderDecoderModel` is not compatible with mps backend. Defaulting to cpu instead\n",
      "Recognizing Layout: 100%|██████████| 14/14 [01:17<00:00,  5.56s/it]\n",
      "Running OCR Error Detection: 100%|██████████| 4/4 [00:00<00:00,  5.28it/s]\n",
      "Detecting bboxes: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s]\n",
      "Recognizing Text:  81%|████████  | 17/21 [02:04<01:23, 20.76s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, paper \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(papers_with_abstracts):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     paper_text = \u001b[43mextract_paper_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     papers_with_abstracts[idx][\u001b[33m\"\u001b[39m\u001b[33mfull_text\u001b[39m\u001b[33m\"\u001b[39m] = paper_text\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtracted full text for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpaper[\u001b[33m'\u001b[39m\u001b[33mfile\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mextract_paper_text\u001b[39m\u001b[34m(pdf_path)\u001b[39m\n\u001b[32m     12\u001b[39m converter = PdfConverter(artifact_dict=model_dict)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Convert the PDF\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m rendered = \u001b[43mconverter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Get the text\u001b[39;00m\n\u001b[32m     18\u001b[39m text, _, _ = text_from_rendered(rendered)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/marker/converters/pdf.py:195\u001b[39m, in \u001b[36mPdfConverter.__call__\u001b[39m\u001b[34m(self, filepath)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filepath: \u001b[38;5;28mstr\u001b[39m | io.BytesIO):\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.filepath_to_str(filepath) \u001b[38;5;28;01mas\u001b[39;00m temp_path:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         document = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28mself\u001b[39m.page_count = \u001b[38;5;28mlen\u001b[39m(document.pages)\n\u001b[32m    197\u001b[39m         renderer = \u001b[38;5;28mself\u001b[39m.resolve_dependencies(\u001b[38;5;28mself\u001b[39m.renderer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/marker/converters/pdf.py:182\u001b[39m, in \u001b[36mPdfConverter.build_document\u001b[39m\u001b[34m(self, filepath)\u001b[39m\n\u001b[32m    180\u001b[39m ocr_builder = \u001b[38;5;28mself\u001b[39m.resolve_dependencies(OcrBuilder)\n\u001b[32m    181\u001b[39m provider = provider_cls(filepath, \u001b[38;5;28mself\u001b[39m.config)\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m document = \u001b[43mDocumentBuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mocr_builder\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m structure_builder_cls = \u001b[38;5;28mself\u001b[39m.resolve_dependencies(StructureBuilder)\n\u001b[32m    186\u001b[39m structure_builder_cls(document)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/marker/builders/document.py:36\u001b[39m, in \u001b[36mDocumentBuilder.__call__\u001b[39m\u001b[34m(self, provider, layout_builder, line_builder, ocr_builder)\u001b[39m\n\u001b[32m     34\u001b[39m line_builder(document, provider)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.disable_ocr:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[43mocr_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m document\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/marker/builders/ocr.py:87\u001b[39m, in \u001b[36mOcrBuilder.__call__\u001b[39m\u001b[34m(self, document, provider)\u001b[39m\n\u001b[32m     83\u001b[39m pages_to_ocr = [page \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m document.pages \u001b[38;5;28;01mif\u001b[39;00m page.text_extraction_method == \u001b[33m'\u001b[39m\u001b[33msurya\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     84\u001b[39m ocr_page_images, block_polygons, block_ids, block_original_texts = (\n\u001b[32m     85\u001b[39m     \u001b[38;5;28mself\u001b[39m.get_ocr_images_polygons_ids(document, pages_to_ocr, provider)\n\u001b[32m     86\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mocr_extraction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpages_to_ocr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mocr_page_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblock_polygons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblock_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblock_original_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/marker/builders/ocr.py:178\u001b[39m, in \u001b[36mOcrBuilder.ocr_extraction\u001b[39m\u001b[34m(self, document, pages, images, block_polygons, block_ids, block_original_texts)\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[38;5;28mself\u001b[39m.recognition_model.disable_tqdm = \u001b[38;5;28mself\u001b[39m.disable_tqdm\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m recognition_results: List[OCRResult] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrecognition_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mocr_task_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolygons\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_polygons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_original_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrecognition_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_recognition_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmath_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdisable_ocr_math\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_repeated_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdrop_repeated_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_sliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2148\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2048\u001b[39;49m\n\u001b[32m    189\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(recognition_results) == \u001b[38;5;28mlen\u001b[39m(images) == \u001b[38;5;28mlen\u001b[39m(pages) == \u001b[38;5;28mlen\u001b[39m(block_ids), (\n\u001b[32m    192\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMismatch in OCR lengths: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(recognition_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(block_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    193\u001b[39m )\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m document_page, page_recognition_result, page_block_ids, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m    195\u001b[39m     pages, recognition_results, block_ids, images\n\u001b[32m    196\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/surya/recognition/__init__.py:431\u001b[39m, in \u001b[36mRecognitionPredictor.__call__\u001b[39m\u001b[34m(self, images, task_names, det_predictor, detection_batch_size, recognition_batch_size, highres_images, bboxes, polygons, input_text, sort_lines, math_mode, return_words, drop_repeated_text, max_sliding_window, max_tokens, filter_tag_list)\u001b[39m\n\u001b[32m    428\u001b[39m flat[\u001b[33m\"\u001b[39m\u001b[33mtask_names\u001b[39m\u001b[33m\"\u001b[39m] = [flat[\u001b[33m\"\u001b[39m\u001b[33mtask_names\u001b[39m\u001b[33m\"\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m predicted_tokens, batch_bboxes, scores, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfoundation_predictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprediction_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mslices\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_texts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtask_names\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecognition_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmath_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmath_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_repeated_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_lookahead_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfoundation_predictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_output_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_sliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_sliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtqdm_desc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRecognizing Text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    442\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Get text and bboxes in structured form\u001b[39;00m\n\u001b[32m    445\u001b[39m bbox_size = \u001b[38;5;28mself\u001b[39m.bbox_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/surya/foundation/__init__.py:827\u001b[39m, in \u001b[36mFoundationPredictor.prediction_loop\u001b[39m\u001b[34m(self, images, input_texts, task_names, batch_size, max_tokens, max_sliding_window, math_mode, drop_repeated_tokens, max_lookahead_tokens, top_k, tqdm_desc)\u001b[39m\n\u001b[32m    825\u001b[39m                     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m     updated_inputs, outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcurrent_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lookahead_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_lookahead_tokens\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    830\u001b[39m     mark_step()\n\u001b[32m    832\u001b[39m     predicted_tokens_cpu = outputs.preds.cpu()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/surya/foundation/__init__.py:341\u001b[39m, in \u001b[36mFoundationPredictor.decode\u001b[39m\u001b[34m(self, current_inputs, max_lookahead_tokens)\u001b[39m\n\u001b[32m    337\u001b[39m cache_position = \u001b[38;5;28mself\u001b[39m.get_cache_position(\n\u001b[32m    338\u001b[39m     input_ids.shape[\u001b[32m1\u001b[39m], \u001b[38;5;28mself\u001b[39m.kv_cache.attention_mask, prefill=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    339\u001b[39m )\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m settings.INFERENCE_MODE():\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_boxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_boxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43membed_boxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed_boxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m processed_output: ContinuousBatchOutput = \u001b[38;5;28mself\u001b[39m.process_outputs(\n\u001b[32m    356\u001b[39m     outputs, max_lookahead_tokens=max_lookahead_tokens\n\u001b[32m    357\u001b[39m )\n\u001b[32m    359\u001b[39m input_ids = processed_output.input_ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/surya/common/surya/__init__.py:468\u001b[39m, in \u001b[36mSuryaModel.forward\u001b[39m\u001b[34m(self, input_ids, image_embeddings, labels, image_tiles, grid_thw, inputs_embeds, attention_mask, position_ids, cache_position, past_key_values, output_hidden_states, output_attentions, use_cache, encoder_chunk_size, cache_idxs, num_valid_tokens, prefill, text_lengths, valid_batch_size, input_boxes, embed_boxes, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    459\u001b[39m causal_mask = \u001b[38;5;28mself\u001b[39m._update_causal_mask(\n\u001b[32m    460\u001b[39m     attention_mask,\n\u001b[32m    461\u001b[39m     inputs_embeds,\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m     output_attentions,\n\u001b[32m    465\u001b[39m )\n\u001b[32m    467\u001b[39m attention_mask = causal_mask\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_idxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    483\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logits_to_keep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/surya/common/surya/decoder/__init__.py:504\u001b[39m, in \u001b[36mSuryaDecoderModel.forward\u001b[39m\u001b[34m(self, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, cache_idxs, num_valid_tokens, text_lengths, prefill, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;66;03m# decoder layers\u001b[39;00m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_idxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    520\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    522\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/surya/common/surya/decoder/__init__.py:302\u001b[39m, in \u001b[36mQwen2DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, cache_idxs, num_valid_tokens, text_lengths, prefill, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    299\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    301\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m hidden_states, self_attn_weights = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_idxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    319\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/surya/common/surya/decoder/__init__.py:188\u001b[39m, in \u001b[36mQwen2Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, cache_idxs, num_valid_tokens, text_lengths, prefill, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    177\u001b[39m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[32m    178\u001b[39m     \u001b[38;5;66;03m# cache_idxs, num_valid_tokens, and prefill add support for our new caching mechanism\u001b[39;00m\n\u001b[32m    179\u001b[39m     cache_kwargs = {\n\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msin\u001b[39m\u001b[33m\"\u001b[39m: sin,\n\u001b[32m    181\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcos\u001b[39m\u001b[33m\"\u001b[39m: cos,\n\u001b[32m   (...)\u001b[39m\u001b[32m    186\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtext_lengths\u001b[39m\u001b[33m\"\u001b[39m: text_lengths,\n\u001b[32m    187\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     key_states, value_states = \u001b[43mpast_key_value\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m attention_interface: Callable = eager_attention_forward\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation != \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/surya/foundation/cache/dynamic_ops.py:83\u001b[39m, in \u001b[36mDynamicOpsCache.update\u001b[39m\u001b[34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m prefill = cache_kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mprefill\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     82\u001b[39m update_fn = \u001b[38;5;28mself\u001b[39m._prefill_update \u001b[38;5;28;01mif\u001b[39;00m prefill \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decode_update\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupdate_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalue_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext_token_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/climate-viewer-ai-bot/.venv/lib/python3.11/site-packages/surya/foundation/cache/dynamic_ops.py:323\u001b[39m, in \u001b[36mDynamicOpsCache._decode_update\u001b[39m\u001b[34m(self, key_cache, value_cache, key_states, value_states, text_token_counts, cache_kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m needs_rotate = slide_amounts > \u001b[32m0\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;66;03m# Rotate the cache if needed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_rotate\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    324\u001b[39m     k_slice = key_cache[:, :, -sliding_window:]  \u001b[38;5;66;03m# shape: [B, H, W, D]\u001b[39;00m\n\u001b[32m    325\u001b[39m     v_slice = value_cache[:, :, -sliding_window:]  \u001b[38;5;66;03m# same shape\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "\n",
    "# Initialize models (do once, reuse for multiple PDFs)\n",
    "model_dict = create_model_dict()\n",
    "converter = PdfConverter(artifact_dict=model_dict)\n",
    "# Usage\n",
    "for idx, paper in enumerate(papers_with_abstracts):\n",
    "    \n",
    "    paper_text = extract_paper_text(pdf_dir + paper[\"file\"], converter, )\n",
    "    papers_with_abstracts[idx][\"full_text\"] = paper_text\n",
    "    print(f\"Extracted full text for {paper['file']}\")\n",
    "    if idx % 10 == 0:\n",
    "        print(f\"Extracted full text for {idx} papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2075f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write papers_with_full_text  to json\n",
    "with open(\"output/papers_with_full_text.json\", \"w\") as f:\n",
    "    json.dump(papers_with_abstracts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0768bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_text_review_prompt(paper_metadata, full_text):\n",
    "    return f\"\"\"You are reviewing a scientific paper for inclusion in a Hawaiian sea level rise database. Analyze the COMPLETE paper text and respond in valid JSON format.\n",
    "\n",
    "=== PAPER INFORMATION ===\n",
    "Title: {paper_metadata.get('title')}\n",
    "Previous Classification: MEDIUM confidence (based on abstract only)\n",
    "\n",
    "=== FULL TEXT ===\n",
    "{full_text}\n",
    "\n",
    "=== YOUR TASK ===\n",
    "Review the complete paper, paying special attention to:\n",
    "1. **Methods section**: Study location, data sources, modeling approaches\n",
    "2. **Results section**: Quantitative findings, measurements, projections\n",
    "3. **Discussion/Conclusions**: Specific implications for Hawaii\n",
    "\n",
    "Determine:\n",
    "- Final relevance (relevant/not relevant)\n",
    "- Confidence level (HIGH/MEDIUM/LOW)\n",
    "- Applicable database layers (maximum 2)\n",
    "- Whether to upgrade/downgrade from abstract-only assessment\n",
    "\n",
    "=== CONFIDENCE CRITERIA ===\n",
    "\n",
    "**HIGH confidence** - All of these must be present:\n",
    "- Study specifically focuses on Hawaiian locations (named islands, cities, or regions)\n",
    "- Contains quantitative data (measurements, rates, projections with numbers)\n",
    "- Results section includes specific Hawaii-relevant findings\n",
    "- Clear methodology described for Hawaii context\n",
    "\n",
    "**MEDIUM confidence** - At least two of these:\n",
    "- Methodology applicable to Hawaii but not Hawaii-specific data\n",
    "- Mentions Hawaii but focuses on broader Pacific/global context\n",
    "- Qualitative findings relevant to Hawaii\n",
    "- Modeling approach transferable to Hawaii\n",
    "\n",
    "**LOW confidence** - Downgrade if:\n",
    "- Hawaii mentioned only in passing or as example\n",
    "- No actionable data or findings\n",
    "- Methodology not applicable to Hawaii\n",
    "\n",
    "=== LAYER DEFINITIONS ===\n",
    "\n",
    "**FLOODING LAYERS** (choose max 2 most relevant):\n",
    "\n",
    "1. **passive_marine_flooding**\n",
    "   Direct ocean water inundation from sea level rise\n",
    "   Keywords: \"marine inundation\", \"coastal flooding\", \"flooded area\", \"inundation zone\", \"bathtub model\", \"passive flooding\", \"flood depth\"\n",
    "   Example: \"3.2 ft SLR results in 1,200 acres of marine flooding\"\n",
    "\n",
    "2. **groundwater_inundation**\n",
    "   Flooding from rising groundwater table\n",
    "   Keywords: \"groundwater\", \"water table rise\", \"subsurface flooding\", \"groundwater emergence\", \"drainage impacts\", \"aquifer\"\n",
    "   Example: \"Water table will reach surface in X years\"\n",
    "\n",
    "3. **low_lying_flooding**\n",
    "   Areas defined by elevation thresholds\n",
    "   Keywords: \"critical elevation\", \"below [X]m/ft\", \"elevation threshold\", \"low-lying areas\", \"DEM analysis\"\n",
    "   Example: \"Areas below 1.5m elevation are vulnerable\"\n",
    "\n",
    "4. **compound_flooding**\n",
    "   Multiple simultaneous flood mechanisms\n",
    "   Keywords: \"compound flooding\", \"multiple mechanisms\", \"combined effects\", \"storm surge + rain\", \"concurrent flooding\"\n",
    "   Example: \"Combined storm surge and high tide flooding\"\n",
    "\n",
    "5. **drainage_backflow**\n",
    "   Stormwater/sewer system flooding\n",
    "   Keywords: \"storm drain\", \"drainage backflow\", \"sewer flooding\", \"infrastructure flooding\", \"drain capacity\"\n",
    "   Example: \"Storm drains will backflow at X cm SLR\"\n",
    "\n",
    "**EROSION/HAZARD LAYERS**:\n",
    "\n",
    "6. **future_erosion_hazard_zone**\n",
    "   Shoreline retreat rates and predictions\n",
    "   Keywords: \"erosion rate\", \"[X] m/year\", \"shoreline change\", \"beach loss\", \"hazard zone\", \"coastal retreat\", \"shoreline position\"\n",
    "   Example: \"Average erosion rate of 0.3 m/year projected\"\n",
    "\n",
    "7. **annual_high_wave_flooding**\n",
    "   Wave-driven coastal flooding events\n",
    "   Keywords: \"wave runup\", \"wave-driven flooding\", \"extreme waves\", \"overwash\", \"wave setup\", \"wave impact\"\n",
    "   Example: \"Annual high wave events cause flooding to X elevation\"\n",
    "\n",
    "8. **emergent_and_shallow_groundwater**\n",
    "   Groundwater near or at surface\n",
    "   Keywords: \"shallow groundwater\", \"emergent groundwater\", \"water table depth\", \"groundwater level\", \"subsurface water\"\n",
    "   Example: \"Groundwater within 0.5m of surface\"\n",
    "\n",
    "=== LAYER SELECTION RULES ===\n",
    "1. Select ONLY layers with explicit evidence in Results/Discussion sections\n",
    "2. Maximum 2 layers per paper - choose the most prominent findings\n",
    "3. If paper covers multiple aspects, prioritize quantitative results over methodology\n",
    "4. Don't assign layers based solely on Methods - findings must be present\n",
    "5. If uncertain between layers, choose the one with more quantitative support\n",
    "\n",
    "=== RESPONSE FORMAT ===\n",
    "Return ONLY valid JSON (no markdown, no extra text):\n",
    "\n",
    "{{\n",
    "    \"relevant\": true,\n",
    "    \"confidence\": \"HIGH\",\n",
    "    \"relevant_layers\": [\"passive_marine_flooding\"],\n",
    "    \"reasoning\": \"Results section (page X) reports 1,200 acres of Oahu coastal area will experience marine inundation under 3.2 ft SLR scenario. Study uses LiDAR elevation data and hydrodynamic modeling specific to Pearl Harbor area. Discussion quantifies impacts on infrastructure and population.\",\n",
    "    \"changed_from_abstract\": true,\n",
    "    \"change_explanation\": \"Upgraded from MEDIUM to HIGH. Abstract mentioned modeling approach but full text reveals extensive Hawaii-specific quantitative results including precise flood extents, elevation thresholds, and infrastructure impacts.\",\n",
    "    \"key_findings\": \"3.2 ft SLR: 1,200 acres flooded, 2,400 structures affected in Oahu coastal zone. Critical elevation threshold: 1.5m NAVD88. Study period: 2020-2100 projections.\",\n",
    "    \"quantitative_data\": {{\n",
    "        \"locations\": [\"Pearl Harbor\", \"Waikiki Beach\", \"Honolulu Harbor\"],\n",
    "        \"measurements\": [\"1,200 acres flood extent\", \"3.2 ft SLR scenario\", \"1.5m NAVD88 threshold\"],\n",
    "        \"time_periods\": [\"2020-2100\"]\n",
    "    }}\n",
    "}}\n",
    "\n",
    "=== IMPORTANT ===\n",
    "- Cite specific page numbers or section names when possible\n",
    "- Quote exact quantitative values from the text\n",
    "- If downgrading confidence, explain why full text reveals less relevance than abstract suggested\n",
    "- If paper is not relevant, set \"relevant\": false and provide brief reasoning\n",
    "- Ensure JSON is valid (use double quotes, proper escaping)\n",
    "\n",
    "Begin your analysis:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3d7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "results = []\n",
    " # Create prompt\n",
    "for paper in successful_extractions:\n",
    "    full_text = extract_full_text_pdfplumber(f\"./pdf_pub/{paper['filename']}\")\n",
    "    prompt = full_text_review_prompt(paper, full_text)\n",
    "    # Call LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"You are an expert in climate science and coastal hazards, specializing in Hawaiian environmental research.\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0.3\n",
    "    )\n",
    "    result = json.loads(response.choices[0].message.content)\n",
    "    result['paper_metadata'] = paper\n",
    "    \n",
    "    results.append(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
